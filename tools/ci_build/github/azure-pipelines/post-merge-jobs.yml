variables:
- name: WIN_CPU_BUILD_MACHINE_POOL_NAME
  value: 'onnxruntime-Win-CPU-2022'
- name: LINUX_CPU_BUILD_MACHINE_POOL_NAME  # name of a variable
  # The public ADO project
  ${{ if startsWith(variables['System.CollectionUri'], 'https://dev.azure.com/onnxruntime/') }}:
    value: 'onnxruntime-Ubuntu2004-AMD-CPU'
  # The private ADO project
  ${{ if or(startsWith(variables['System.CollectionUri'], 'https://dev.azure.com/aiinfra/'),startsWith(variables['System.CollectionUri'], 'https://aiinfra.visualstudio.com/')) }}:
    value: 'aiinfra-Linux-CPU'

resources:
  repositories:
  - repository: manylinux
    type: Github
    endpoint: Microsoft
    name: pypa/manylinux
    ref: aead4d751c2101e23336aa73f2380df83e7a13f3

stages:
- ${{ if or(startsWith(variables['System.CollectionUri'], 'https://dev.azure.com/aiinfra/'),startsWith(variables['System.CollectionUri'], 'https://aiinfra.visualstudio.com/')) }}:
  - template: templates/web-ci.yml
    parameters:
      NpmPackagingMode: 'dev'
      IsReleasePipeline: true
      PoolName: 'aiinfra-Win-CPU-2022-web-beta'
      BuildStaticLib: true
      ExtraBuildArgs: ''

# This stage is to test if the combined build works on
# o Windows ARM64
# o Windows ARM64EC
# o Windows x64
# o Windows x86
# Now we don't have coverage for ARM64EC yet. Will add it.
- template: templates/win-ci.yml
  parameters:
    DoCompliance: false
    DoEsrp: false
    stage_name_suffix: CPU_x86_default
    EnvSetupScript: setup_env_x86.bat
    buildArch: x86
    msbuildPlatform: Win32
    packageName: x86
    buildparameter: --use_extensions --enable_onnx_tests
    runTests: true
    buildJava: false
    buildNodejs: false
    ort_build_pool_name: ${{variables.WIN_CPU_BUILD_MACHINE_POOL_NAME}}

- template: templates/win-ci.yml
  parameters:
    DoCompliance: false
    DoEsrp: false
    stage_name_suffix: CPU_arm64_default
    EnvSetupScript: setup_env.bat
    buildArch: x64
    msbuildPlatform: arm64
    packageName: arm64
    buildparameter: --build_nodejs --arm64 --use_extensions  --enable_onnx_tests --path_to_protoc_exe $(Build.BinariesDirectory)\RelWithDebInfo\installed\bin\protoc.exe
    runTests: false
    buildJava: false
    buildNodejs: true
    ort_build_pool_name: ${{variables.WIN_CPU_BUILD_MACHINE_POOL_NAME}}

- template: templates/win-ci.yml
  parameters:
    DoCompliance: false
    DoEsrp: false
    stage_name_suffix: CPU_x64_default
    EnvSetupScript: setup_env.bat
    buildArch: x64
    msbuildPlatform: x64
    packageName: x64
    buildparameter: --build_java --build_nodejs --use_extensions  --enable_onnx_tests
    runTests: true
    buildJava: true
    buildNodejs: true
    ort_build_pool_name: ${{variables.WIN_CPU_BUILD_MACHINE_POOL_NAME}}

- stage: Mimalloc
  dependsOn: [ ]
  jobs:
  - template: templates/jobs/win-ci-vs-2022-job.yml
    parameters:
      BuildConfig: 'Debug'
      EnvSetupScript: setup_env.bat
      buildArch: x64
      additionalBuildFlags: --disable_memleak_checker --use_mimalloc
      msbuildPlatform: x64
      isX86: false
      job_name_suffix: x64_mimalloc
      RunOnnxRuntimeTests: true
      RunStaticCodeAnalysis: false
      isTraining: false
      ORT_EP_NAME: CPU
      GenerateDocumentation: false
      EnablePython: false
      MachinePool: ${{variables.WIN_CPU_BUILD_MACHINE_POOL_NAME}}

- stage: NoAbseil
  dependsOn: [ ]
  jobs:
  - template: templates/jobs/win-ci-vs-2022-job.yml
    parameters:
      BuildConfig: 'Debug'
      EnvSetupScript: setup_env.bat
      buildArch: x64
      additionalBuildFlags: --cmake_extra_defines onnxruntime_DISABLE_ABSEIL=ON
      msbuildPlatform: x64
      isX86: false
      job_name_suffix: x64_no_absl
      RunOnnxRuntimeTests: true
      RunStaticCodeAnalysis: false
      isTraining: false
      ORT_EP_NAME: CPU
      GenerateDocumentation: false
      EnablePython: false
      MachinePool: ${{variables.WIN_CPU_BUILD_MACHINE_POOL_NAME}}

- stage: MinimalBuildWithNoExceptions
  dependsOn: [ ]
  jobs:
  - template: templates/jobs/win-ci-vs-2022-job.yml
    parameters:
      BuildConfig: 'Debug'
      EnvSetupScript: setup_env.bat
      buildArch: x64
      additionalBuildFlags: --build_shared_lib --minimal_build --disable_exceptions
      msbuildPlatform: x64
      isX86: false
      job_name_suffix: x64_minimal_no_exception
      RunOnnxRuntimeTests: true
      RunStaticCodeAnalysis: false
      isTraining: false
      ORT_EP_NAME: CPU
      GenerateDocumentation: false
      EnablePython: false
      MachinePool: ${{variables.WIN_CPU_BUILD_MACHINE_POOL_NAME}}

- stage: DebugNodeInputsOutputs
  dependsOn: [ ]
  jobs:
  - template: templates/jobs/win-ci-vs-2022-job.yml
    parameters:
      BuildConfig: 'Debug'
      EnvSetupScript: setup_env.bat
      buildArch: x64
      additionalBuildFlags: --build_shared_lib --cmake_extra_defines onnxruntime_DEBUG_NODE_INPUTS_OUTPUTS=ON
      msbuildPlatform: x64
      isX86: false
      job_name_suffix: x64_debug_node_input_output
      RunOnnxRuntimeTests: true
      RunStaticCodeAnalysis: false
      isTraining: false
      ORT_EP_NAME: CPU
      GenerateDocumentation: false
      EnablePython: false
      MachinePool: ${{variables.WIN_CPU_BUILD_MACHINE_POOL_NAME}}

- stage: CUDA
  dependsOn: [ ]
  jobs:
  - job: CUDA_NO_CONTRIB_OPS
    timeoutInMinutes: 120
    variables:
      skipComponentGovernanceDetection: true      
    workspace:
      clean: all
    pool: onnxruntime-Ubuntu2004-AMD-CPU
    steps:
    - task: mspremier.PostBuildCleanup.PostBuildCleanup-task.PostBuildCleanup@3
      displayName: 'Clean Agent Directories'
      condition: always()

    - checkout: self
      clean: true
      submodules: none

    - template: templates/get-docker-image-steps.yml
      parameters:
        Dockerfile: tools/ci_build/github/linux/docker/Dockerfile.manylinux2014_cuda11
        Context: tools/ci_build/github/linux/docker
        DockerBuildArgs: "--network=host --build-arg POLICY=manylinux2014 --build-arg PLATFORM=x86_64 --build-arg BASEIMAGE=${{variables.common_cuda_baseimg}} --build-arg DEVTOOLSET_ROOTPATH=/opt/rh/devtoolset-11/root --build-arg PREPEND_PATH=/opt/rh/devtoolset-11/root/usr/bin: --build-arg LD_LIBRARY_PATH_ARG=/opt/rh/devtoolset-11/root/usr/lib64:/opt/rh/devtoolset-11/root/usr/lib:/opt/rh/devtoolset-11/root/usr/lib64/dyninst:/opt/rh/devtoolset-11/root/usr/lib/dyninst:/usr/local/lib64 --build-arg BUILD_UID=$( id -u )"
        Repository: onnxruntimecuda11build    

    - task: CmdLine@2
      inputs:
        script: |      
          docker run -e CC=/opt/rh/devtoolset-11/root/usr/bin/cc -e CXX=/opt/rh/devtoolset-11/root/usr/bin/c++ -e CFLAGS="-Wp,-D_FORTIFY_SOURCE=2 -Wp,-D_GLIBCXX_ASSERTIONS -fstack-protector-strong -fstack-clash-protection -fcf-protection -O3 -Wl,--strip-all" -e CXXFLAGS="-Wp,-D_FORTIFY_SOURCE=2 -Wp,-D_GLIBCXX_ASSERTIONS -fstack-protector-strong -fstack-clash-protection -fcf-protection -O3 -Wl,--strip-all" --rm \
            --volume /data/onnx:/data/onnx:ro \
            --volume $(Build.SourcesDirectory):/onnxruntime_src \
            --volume $(Build.BinariesDirectory):/build \
            --volume /data/models:/build/models:ro \
            --volume $(Pipeline.Workspace)/ccache:/cache \
            -e ALLOW_RELEASED_ONNX_OPSET_ONLY=0 \
            -e NIGHTLY_BUILD \
            -e BUILD_BUILDNUMBER \
            -e CCACHE_DIR=/cache \
            onnxruntimecuda11build \
              /opt/python/cp38-cp38/bin/python3 /onnxruntime_src/tools/ci_build/build.py \
              --build_dir /build --cmake_generator Ninja \
              --config Release --update --build \
              --skip_submodule_sync \
              --build_shared_lib \
              --parallel \
              --build_wheel \
              --enable_onnx_tests --use_cuda --cuda_version=${{variables.common_cuda_version}} --cuda_home=/usr/local/cuda-${{variables.common_cuda_version}} --cudnn_home=/usr/local/cuda-${{variables.common_cuda_version}} \
              --disable_contrib_ops \
              --cmake_extra_defines CMAKE_CUDA_HOST_COMPILER=/opt/rh/devtoolset-11/root/usr/bin/cc  CMAKE_CUDA_ARCHITECTURES=75

#Generate test coverage report and publish the data to a Cloud database. Only runs daily.
- stage: CodeCoverage
  dependsOn: [ ]
  jobs:
  - job: CodeCoverage
    workspace:
      clean: all
    timeoutInMinutes: 150
    variables:
      skipComponentGovernanceDetection: true
    pool: ${{variables.LINUX_CPU_BUILD_MACHINE_POOL_NAME}}
    steps:
    - template: templates/set-version-number-variables-step.yml

    - task: CmdLine@2
      inputs:
        script: |
          set -e
          ln -s /data/models .
          #Build onnxruntime and run the instrumented program(unitests)
          LLVM_PROFILE_FILE="%p.profraw" CFLAGS="-g -fprofile-instr-generate -fcoverage-mapping" CXXFLAGS="-g -fprofile-instr-generate -fcoverage-mapping" CC=clang CXX=clang++  python3 $(Build.SourcesDirectory)/tools/ci_build/build.py --build_dir=$(Build.BinariesDirectory) --config Debug --parallel --skip_submodule_sync --build_shared_lib --enable_onnx_tests --cmake_extra_defines RUN_MODELTEST_IN_DEBUG_MODE=ON

          cd Debug
          ./onnxruntime_mlas_test
          #Merge the multiple prof data into a single indexed profile data file
          llvm-profdata merge -sparse -o ort.profdata *.profraw
          #Create coverage report, output the result to 'report.json'
          llvm-cov export -summary-only -instr-profile=ort.profdata onnxruntime_test_all -object onnxruntime_mlas_test -object onnxruntime_api_tests_without_env -object onnx_test_runner -object onnxruntime_shared_lib_test -object onnxruntime_global_thread_pools_test -object onnxruntime_api_tests_without_env $(Build.SourcesDirectory)/include/onnxruntime $(Build.SourcesDirectory)/onnxruntime/core $(Build.SourcesDirectory)/onnxruntime/contrib_ops > $(Build.BinariesDirectory)/report.json

          llvm-cov show -instr-profile=ort.profdata onnxruntime_test_all -object onnxruntime_mlas_test -object onnxruntime_api_tests_without_env -object onnx_test_runner -object onnxruntime_shared_lib_test -object onnxruntime_global_thread_pools_test -object onnxruntime_api_tests_without_env $(Build.SourcesDirectory)/include/onnxruntime $(Build.SourcesDirectory)/onnxruntime/core $(Build.SourcesDirectory)/onnxruntime/contrib_ops --format=html -output-dir=$(Build.ArtifactStagingDirectory)
        workingDirectory: $(Build.BinariesDirectory)

    - ${{ if or(startsWith(variables['System.CollectionUri'], 'https://dev.azure.com/aiinfra/'),startsWith(variables['System.CollectionUri'], 'https://aiinfra.visualstudio.com/')) }}:
      - task: AzureCLI@2
        displayName: 'Azure CLI'
        inputs:
          azureSubscription: AIInfraBuildOnnxRuntimeOSS
          scriptType: bash
          scriptPath: $(Build.SourcesDirectory)/tools/ci_build/github/linux/upload_code_coverage_data.sh
          arguments: '"$(Build.BinariesDirectory)/report.json" "https://aiinfra.visualstudio.com/Lotus/_build/results?buildId=$(Build.BuildId)" x64 linux default'
          workingDirectory: '$(Build.BinariesDirectory)'

      - task: PublishPipelineArtifact@1
        displayName: 'Publish Pipeline Artifact'
        inputs:
          targetPath: '$(Build.ArtifactStagingDirectory)'
          artifact: html
  - ${{ if or(startsWith(variables['System.CollectionUri'], 'https://dev.azure.com/aiinfra/'),startsWith(variables['System.CollectionUri'], 'https://aiinfra.visualstudio.com/')) }}:
    - template: templates/upload-code-coverage-data.yml

- stage: AndroidCustomBuildScript
  dependsOn: [ ]
  jobs:
  - job: AndroidCustomBuildScript
    workspace:
      clean: all
    pool: ${{variables.LINUX_CPU_BUILD_MACHINE_POOL_NAME}}
    variables:
      dockerImageTag: onnxruntime-android-custom-build
    steps:
    - checkout: self
      submodules: false

    - task: UsePythonVersion@0
      inputs:
        versionSpec: '3.8'
        addToPath: true
        architecture: x64

    - task: CmdLine@2
      displayName: 'Run build_custom_android_package.py'
      inputs:
        script: |
          "$(Build.SourcesDirectory)/tools/android_custom_build/build_custom_android_package.py" \
            --docker_image_tag=$(dockerImageTag) \
            "$(Build.BinariesDirectory)/custom_android_package"
        workingDirectory: '$(Build.BinariesDirectory)'

    - task: CmdLine@2
      displayName: 'Clean up docker image'
      inputs:
        script: docker image rm $(dockerImageTag)
        workingDirectory: '$(Build.BinariesDirectory)'
      condition: succeededOrFailed()
